{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "DQN_project_MVA_Fatma_MOALLA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_kmGR8oe4r9",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1xlF2AjJK4a",
        "colab_type": "code",
        "outputId": "19d20412-61d8-4db4-d02c-c53f7c33cd82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!pip install scikit-video"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.6/dist-packages (1.1.11)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4lLeK4Se4sB",
        "colab_type": "code",
        "outputId": "59110985-80b7-4607-fb9c-4e397111cd28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!sudo apt install skvideo"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package skvideo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FI2Lpz-e4sR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd, Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8bAiQr-e4sX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuxwjzgfe4sZ",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmLIcqFLe4sa",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASuTr-51e4sb",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDdie1MNe4sc",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy2WnnQpe4se",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNFUVrIUe4sf",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVKdCBH1e4sg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8-yJohYe4sl",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHgI3bZYe4sm",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yidUvsrae4so",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDXjds9Me4sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTtKosFze4st",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<font color='blue'>__Question 1__:</font>\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdUbQrdAe4su",
        "colab_type": "text"
      },
      "source": [
        "1) The act function , given the current state of the game and the type of phase either training or testing, returns the action to take at the next step.\n",
        "* For the training phase : we use an $\\epsilon$ greedy algorithm that return a random action with a probability of $\\epsilon$ and return an action based on the learnt policy with a pobability of $1-\\epsilon$.\n",
        "* For the testing phase : the agent takes the best action he learnt from the current state.\n",
        "\n",
        "2) The ```epsilon``` importance resides in its role to push the agent to explore the whole environment and prevents from being stuck in local maximas for the reward.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01KXBzOEe4sw",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxwpZ8NEe4sx",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMTgoaoEe4sy",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3vPbR6Je4sz",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI5VsDnwe4s0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCWd4X9Pe4s4",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZDhqEB6e4s5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=50 # set small when debugging\n",
        "epochs_test= 15 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5UwnoXRe4s8",
        "colab_type": "text"
      },
      "source": [
        "<font color='blue'>__Question 2__</font> Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_EhEo_Me4s9",
        "colab_type": "text"
      },
      "source": [
        "- ```position``` is an NxN matrix, used to represent the position of the rat at step t. The position of the rat is modelled by the value 1. The value 0 corresponds to alloweed states and the value 1 corresponds to value the forbidden states (borders of the grid)\n",
        "\n",
        "- ```board``` is a NxN matrix taht reprensets the reward for each cell of the grid: -1 for poisonous cells and 0.5 for positive cells.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCRQPSEKe4s-",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx6WduTFe4tA",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<font color='blue'> __Question 3__</font> Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zDmtRuue4tC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.random.randint(self.n_action)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0oj_xSYe4tF",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "<font color='blue'>__Question 4__</font> Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDlC6e-Ge4tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "    \n",
        "        state = env.reset()\n",
        "        # Initialization at each epoch\n",
        "        game_over = False\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        \n",
        "        while not game_over:\n",
        "            \n",
        "            #Agent takes an action\n",
        "            action=agent.act(state)\n",
        "            #Update: next state, reward and a boolean variable indicating the end(or not) of the game from the environment\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        " \n",
        "            \n",
        "            #Update the score\n",
        "            if reward>0:\n",
        "                win = win + reward\n",
        "            if reward<0:\n",
        "                lose = lose - reward\n",
        "        \n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAaoGJl_e4tS",
        "colab_type": "code",
        "outputId": "3f49abe8-52b1-40bd-a77c-ee6a60133146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 11.0/12.0. Average score (-1.0)\n",
            "Win/lose count 11.0/12.0. Average score (-1.0)\n",
            "Win/lose count 11.0/15.0. Average score (-2.0)\n",
            "Win/lose count 14.0/11.0. Average score (-0.75)\n",
            "Win/lose count 7.5/13.0. Average score (-1.7)\n",
            "Win/lose count 7.0/19.0. Average score (-3.4166666666666665)\n",
            "Win/lose count 11.5/18.0. Average score (-3.857142857142857)\n",
            "Win/lose count 14.5/14.0. Average score (-3.3125)\n",
            "Win/lose count 9.5/7.0. Average score (-2.6666666666666665)\n",
            "Win/lose count 15.5/18.0. Average score (-2.65)\n",
            "Win/lose count 12.0/15.0. Average score (-2.6818181818181817)\n",
            "Win/lose count 8.5/14.0. Average score (-2.9166666666666665)\n",
            "Win/lose count 13.5/19.0. Average score (-3.1153846153846154)\n",
            "Win/lose count 10.5/8.0. Average score (-2.7142857142857144)\n",
            "Win/lose count 12.0/10.0. Average score (-2.4)\n",
            "Final score: -2.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjzO5um5e4tX",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yKXh0MWe4tZ",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "<font color='blue'>__Question 5__ </font>Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cVGdAKXe4ta",
        "colab_type": "text"
      },
      "source": [
        "**1) Q function expression**\n",
        "\n",
        "$$ Q^\\pi(s,a) = E_{p^\\pi}[\\sum_{t=0}^\\infty \\gamma^t r_t(s_t,a_t)| s_0 =s, a_0=a] \\\\ = r(s,a) + E_{p^\\pi}[\\sum_{t=1}^\\infty \\gamma^t r(s_t,a_t)| s_0 =s, a_0=a]   $$\n",
        "                \n",
        "With a variable change $k=t-1$ :\n",
        "\n",
        "$ Q^\\pi(s,a) = r(s,a) + \\gamma E_{p^\\pi}[\\sum_{k=0}^\\infty \\gamma^k r(s_k,a_k)| s_0 =s, a_0=a] \\\\= r(s,a) + \\gamma E_{(s',a')\\sim p(.|s,a)}[E_{p^\\pi}[\\sum_{k=0}^\\infty \\gamma^t r(s_k,a_k)| s_0 =s', a_0=a']]\\\\ = E_{(s',a')\\sim p(.|s,a)}[E_{p^\\pi}[ r(s,a) + \\sum_{k=0}^\\infty \\gamma^k r(s_k,a_k)| s_0 =s', a_0=a']] \\\\=  E_{(s',a')\\sim p(.|s,a)}[r(s,a) + \\gamma  Q^\\pi(s',a') ]$\n",
        "\n",
        "\n",
        "**2) Optimal Q function expression**\n",
        "\n",
        "We know that the optimal policy (if it exists) $\\pi^*$ is : $\\pi^*(s') = argmax_{a'} Q^*(s',a') $\n",
        "\n",
        "\n",
        "and we know that :\n",
        "\n",
        "$ Q^*(s,a) = E_{(s',a')\\sim \\pi^*(.|s,a)}[r(s,a) + \\gamma max_\\pi Q^\\pi(s',a')] \\\\= E_{(s',a')\\sim p(.|s,a)}[ r(s,a) + \\gamma Q^*(s',a')]\\\\= E_{(s'\\sim p^*(.|s,a),a'\\sim \\pi^*(.|s'))}[r(s,a) + \\gamma Q^*(s',a')] $\n",
        "\n",
        "since $\\pi^* $ is deterministic, then:\n",
        "\n",
        "$ Q^*(s,a) = E_{(s'\\sim p^*(.|s,a),a'=\\pi^*(s'))}[r(s,a) + \\gamma Q^*(s',a')] \\\\ =  E_{s'\\sim \\pi^*(.|s,a)}[r(s,a) + \\gamma max_{a'}Q^*(s',a')]  $\n",
        "\n",
        "\n",
        "\n",
        "**3) Loss function expression**\n",
        "\n",
        "The ultimate goal is to approximate $Q^*(s,a)$ , therefore we can define the following loss function :\n",
        "\n",
        "$$ \\mathcal{L}(\\theta) = E_{s'\\sim \\pi^*(.|s,a)}[||Q^*(s,a) - Q(s,a,\\theta)||^2] $$\n",
        "\n",
        "By using the result of the previous question $$Q^*(s,a) = E_{s'\\sim \\pi^*(.|s,a)}[r(s,a) + \\gamma max_{a'}Q^*(s',a')] $$\n",
        "\n",
        "The final loss is therefore:\n",
        "\n",
        "$$ \\mathcal{L}(\\theta) = E_{s'\\sim \\pi^*(.|s,a)}[|| r(s,a) + \\gamma max_{a'}Q^*(s',a') - Q(s,a,\\theta) ||^2]$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Armh5Pnce4tb",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "<font color='blue'>__Question 6__ </font>Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nHj3EjacHSVb",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        if len(self.memory) < self.max_memory:\n",
        "            self.memory.append(m)\n",
        "        \n",
        "\n",
        "    def random_access(self):\n",
        "        return self.memory[np.random.randint(len(self.memory))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOP7Wm32e4th",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb-8GelSe4ti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "\n",
        "            #Agent takes an action\n",
        "            action=agent.act(state)\n",
        "            \n",
        "            #Update: next state, reward and a boolean variable indicating the end(or not) of the game from the environment\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        " \n",
        "            \n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "        # Save as a mp4\n",
        "        if (e) % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdEMut02e4tm",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<font color='blue'>__Question 7__</font> Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOnL3W6ve4tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(s[None]))\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            # Update from environment\n",
        "            s_, n_s_, a_, r_, game_over_=self.memory.random_access()\n",
        "            # Store current values\n",
        "            states[i] = s_\n",
        "            target_q[i] = self.model.predict(s_[None])\n",
        "            \n",
        "            #  Update Q_star\n",
        "            if game_over_:\n",
        "                target_q[i,a_] = r_\n",
        "               \n",
        "            else:\n",
        "                #q_hat = self.model.predict(s_.reshape([1,s_.shape[0],s_.shape[1],s_.shape[2]]))[0]\n",
        "                q_hat = self.model.predict(n_s_[None])\n",
        "                target_q[i,a_] = r_+ self.discount* np.max(q_hat,axis=1)\n",
        "\n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -5, 5)\n",
        "\n",
        "        l = self.model.train_on_batch(states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"adam\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        model = Sequential()\n",
        "        model.add(Flatten(input_shape=(5,5,self.n_state, )))\n",
        "        model.add(Dense(32, input_shape=(5*5*self.n_state, ), activation= 'relu', kernel_regularizer = l2(1e-4)))\n",
        "        model.add(Dense(4,input_shape=(5*5*self.n_state, ), activation= 'relu', kernel_regularizer = l2(1e-4)))      \n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4,momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "lJw8FJ_ne4ts",
        "colab_type": "code",
        "outputId": "bd0782f2-4e60-4806-a7f3-fa41fb98cfef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=0.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/050 | Loss 0.0126 | Win/lose count 7.0/4.0 (3.0)\n",
            "Epoch 001/050 | Loss 0.0070 | Win/lose count 1.0/2.0 (-1.0)\n",
            "Epoch 002/050 | Loss 0.0112 | Win/lose count 6.0/3.0 (3.0)\n",
            "Epoch 003/050 | Loss 0.0177 | Win/lose count 3.5/8.0 (-4.5)\n",
            "Epoch 004/050 | Loss 0.0103 | Win/lose count 2.0/4.0 (-2.0)\n",
            "Epoch 005/050 | Loss 0.0209 | Win/lose count 5.5/1.0 (4.5)\n",
            "Epoch 006/050 | Loss 0.2079 | Win/lose count 8.0/4.0 (4.0)\n",
            "Epoch 007/050 | Loss 0.0220 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 008/050 | Loss 0.0101 | Win/lose count 1.0/0 (1.0)\n",
            "Epoch 009/050 | Loss 0.1922 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 010/050 | Loss 0.2011 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 011/050 | Loss 0.0087 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 012/050 | Loss 0.0108 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 013/050 | Loss 0.1924 | Win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 014/050 | Loss 0.0124 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 015/050 | Loss 0.0128 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 016/050 | Loss 0.0067 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 017/050 | Loss 0.0079 | Win/lose count 7.0/1.0 (6.0)\n",
            "Epoch 018/050 | Loss 0.0091 | Win/lose count 5.0/1.0 (4.0)\n",
            "Epoch 019/050 | Loss 0.0083 | Win/lose count 12.0/7.0 (5.0)\n",
            "Epoch 020/050 | Loss 0.0086 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 021/050 | Loss 0.1888 | Win/lose count 8.5/1.0 (7.5)\n",
            "Epoch 022/050 | Loss 0.0077 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 023/050 | Loss 0.0058 | Win/lose count 6.0/4.0 (2.0)\n",
            "Epoch 024/050 | Loss 0.0150 | Win/lose count 2.5/5.0 (-2.5)\n",
            "Epoch 025/050 | Loss 0.0101 | Win/lose count 6.0/1.0 (5.0)\n",
            "Epoch 026/050 | Loss 0.0077 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 027/050 | Loss 0.0059 | Win/lose count 4.0/1.0 (3.0)\n",
            "Epoch 028/050 | Loss 0.0080 | Win/lose count 2.5/0 (2.5)\n",
            "Epoch 029/050 | Loss 0.0077 | Win/lose count 5.5/1.0 (4.5)\n",
            "Epoch 030/050 | Loss 0.0101 | Win/lose count 8.5/2.0 (6.5)\n",
            "Epoch 031/050 | Loss 0.0069 | Win/lose count 8.0/0 (8.0)\n",
            "Epoch 032/050 | Loss 0.1520 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 033/050 | Loss 0.0076 | Win/lose count 6.5/2.0 (4.5)\n",
            "Epoch 034/050 | Loss 0.0082 | Win/lose count 10.5/6.0 (4.5)\n",
            "Epoch 035/050 | Loss 0.0072 | Win/lose count 10.0/2.0 (8.0)\n",
            "Epoch 036/050 | Loss 0.1696 | Win/lose count 6.0/3.0 (3.0)\n",
            "Epoch 037/050 | Loss 0.0066 | Win/lose count 7.5/1.0 (6.5)\n",
            "Epoch 038/050 | Loss 0.0083 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 039/050 | Loss 0.0070 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 040/050 | Loss 0.1655 | Win/lose count 4.5/0 (4.5)\n",
            "Epoch 041/050 | Loss 0.0069 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 042/050 | Loss 0.0071 | Win/lose count 5.0/5.0 (0.0)\n",
            "Epoch 043/050 | Loss 0.0055 | Win/lose count 8.0/4.0 (4.0)\n",
            "Epoch 044/050 | Loss 0.0067 | Win/lose count 3.5/0 (3.5)\n",
            "Epoch 045/050 | Loss 0.1010 | Win/lose count 9.0/3.0 (6.0)\n",
            "Epoch 046/050 | Loss 0.0085 | Win/lose count 8.0/4.0 (4.0)\n",
            "Epoch 047/050 | Loss 0.0055 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 048/050 | Loss 0.0075 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 049/050 | Loss 0.1058 | Win/lose count 9.5/4.0 (5.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v3575WIe4tw",
        "colab_type": "text"
      },
      "source": [
        "<font color='green'> **Comments** </font> Finetuning on:\n",
        "\n",
        "- For Learning Rate :  lr = 0.1, lr = 0.2 and lr=0.05\n",
        "- For batch size 16 , 32, 64 \n",
        "- Memory size 2000, 5000\n",
        "- Optimizer: Sgd or Adam\n",
        "\n",
        "--> The best values are: **LR=0.1, batch_size=32,Memory_size=2000, Sgd**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmExeMxQe4tx",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "<font color='blue'>__Question 8__</font> Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81v0iYU-e4ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model=Sequential()\n",
        "        model.add(Conv2D(32, kernel_size=3, input_shape=(5,5,self.n_state,),activation='relu',kernel_regularizer = l2(1e-4)))\n",
        "        model.add(Conv2D(64, kernel_size=3, activation='relu',kernel_regularizer = l2(1e-4)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(units = 4,kernel_regularizer = l2(1e-4)))\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4,momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpn65Q7Me4t1",
        "colab_type": "code",
        "outputId": "67ad6b0e-4a2c-4b54-ea83-a67e77dbfde8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=0.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/050 | Loss 0.0065 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 001/050 | Loss 0.0108 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 002/050 | Loss 0.0103 | Win/lose count 3.0/5.0 (-2.0)\n",
            "Epoch 003/050 | Loss 0.0131 | Win/lose count 1.0/0 (1.0)\n",
            "Epoch 004/050 | Loss 0.0072 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 005/050 | Loss 0.0114 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 006/050 | Loss 0.0098 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 007/050 | Loss 0.0127 | Win/lose count 4.5/5.0 (-0.5)\n",
            "Epoch 008/050 | Loss 0.0080 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 009/050 | Loss 0.0071 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 010/050 | Loss 0.0088 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 011/050 | Loss 0.3398 | Win/lose count 5.5/1.0 (4.5)\n",
            "Epoch 012/050 | Loss 0.0099 | Win/lose count 4.5/4.0 (0.5)\n",
            "Epoch 013/050 | Loss 0.0094 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 014/050 | Loss 0.0071 | Win/lose count 6.0/3.0 (3.0)\n",
            "Epoch 015/050 | Loss 0.0091 | Win/lose count 10.0/8.0 (2.0)\n",
            "Epoch 016/050 | Loss 0.1608 | Win/lose count 8.0/3.0 (5.0)\n",
            "Epoch 017/050 | Loss 0.0083 | Win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 018/050 | Loss 0.0074 | Win/lose count 7.0/4.0 (3.0)\n",
            "Epoch 019/050 | Loss 0.1565 | Win/lose count 4.5/0 (4.5)\n",
            "Epoch 020/050 | Loss 0.1679 | Win/lose count 8.0/7.0 (1.0)\n",
            "Epoch 021/050 | Loss 0.0094 | Win/lose count 7.0/7.0 (0.0)\n",
            "Epoch 022/050 | Loss 0.0144 | Win/lose count 8.5/1.0 (7.5)\n",
            "Epoch 023/050 | Loss 0.0092 | Win/lose count 7.0/2.0 (5.0)\n",
            "Epoch 024/050 | Loss 0.0090 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 025/050 | Loss 0.0092 | Win/lose count 6.5/1.0 (5.5)\n",
            "Epoch 026/050 | Loss 0.1705 | Win/lose count 7.5/5.0 (2.5)\n",
            "Epoch 027/050 | Loss 0.3326 | Win/lose count 11.5/0 (11.5)\n",
            "Epoch 028/050 | Loss 0.0109 | Win/lose count 10.5/2.0 (8.5)\n",
            "Epoch 029/050 | Loss 0.0076 | Win/lose count 9.0/2.0 (7.0)\n",
            "Epoch 030/050 | Loss 0.0073 | Win/lose count 1.0/2.0 (-1.0)\n",
            "Epoch 031/050 | Loss 0.0072 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 032/050 | Loss 0.0099 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 033/050 | Loss 0.1222 | Win/lose count 9.5/2.0 (7.5)\n",
            "Epoch 034/050 | Loss 0.0121 | Win/lose count 6.5/2.0 (4.5)\n",
            "Epoch 035/050 | Loss 0.0084 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 036/050 | Loss 0.0073 | Win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 037/050 | Loss 0.0079 | Win/lose count 3.0/0 (3.0)\n",
            "Epoch 038/050 | Loss 0.0071 | Win/lose count 6.5/2.0 (4.5)\n",
            "Epoch 039/050 | Loss 0.1368 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 040/050 | Loss 0.0075 | Win/lose count 9.0/2.0 (7.0)\n",
            "Epoch 041/050 | Loss 0.0066 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 042/050 | Loss 0.0083 | Win/lose count 6.0/1.0 (5.0)\n",
            "Epoch 043/050 | Loss 0.0096 | Win/lose count 8.0/3.0 (5.0)\n",
            "Epoch 044/050 | Loss 0.0074 | Win/lose count 9.5/0 (9.5)\n",
            "Epoch 045/050 | Loss 0.0069 | Win/lose count 13.5/4.0 (9.5)\n",
            "Epoch 046/050 | Loss 0.0062 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 047/050 | Loss 0.0065 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 048/050 | Loss 0.0094 | Win/lose count 10.5/2.0 (8.5)\n",
            "Epoch 049/050 | Loss 0.1676 | Win/lose count 6.5/1.0 (5.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_lJUofSe4t4",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "<font color='blue'>__Question 9__</font> Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndLCd5sze4t5",
        "colab_type": "code",
        "outputId": "f48ae977-8e49-4661-f7d2-5597c820793c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "\n",
        "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=0.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "epochs_test = 10\n",
        "agent_fc = DQN_FC(size, lr=0.1, epsilon = 0.1, memory_size=2000, batch_size = 132)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 5.0/2.0. Average score (3.0)\n",
            "Win/lose count 2.5/0. Average score (2.75)\n",
            "Win/lose count 6.5/2.0. Average score (3.3333333333333335)\n",
            "Win/lose count 5.5/2.0. Average score (3.375)\n",
            "Win/lose count 6.0/4.0. Average score (3.1)\n",
            "Win/lose count 8.5/6.0. Average score (3.0)\n",
            "Win/lose count 9.0/4.0. Average score (3.2857142857142856)\n",
            "Win/lose count 1.0/2.0. Average score (2.75)\n",
            "Win/lose count 8.5/3.0. Average score (3.0555555555555554)\n",
            "Win/lose count 8.0/1.0. Average score (3.45)\n",
            "Final score: 3.45\n",
            "Test of the FC\n",
            "Win/lose count 4.5/4.0. Average score (0.5)\n",
            "Win/lose count 6.0/1.0. Average score (2.75)\n",
            "Win/lose count 5.5/15.0. Average score (-1.3333333333333333)\n",
            "Win/lose count 6.5/2.0. Average score (0.125)\n",
            "Win/lose count 4.5/3.0. Average score (0.4)\n",
            "Win/lose count 5.5/5.0. Average score (0.4166666666666667)\n",
            "Win/lose count 6.5/6.0. Average score (0.42857142857142855)\n",
            "Win/lose count 2.5/4.0. Average score (0.1875)\n",
            "Win/lose count 3.5/2.0. Average score (0.3333333333333333)\n",
            "Win/lose count 3.5/2.0. Average score (0.45)\n",
            "Final score: 0.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adovzEQye4t8",
        "colab_type": "code",
        "outputId": "9d05674b-8958-40fd-cc70-5ca47b34c14b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "HTML(display_videos('cnn_test9.mp4'))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuwUNBgAe4uA",
        "colab_type": "code",
        "outputId": "8524f473-8cc1-4b96-a88c-a09dd8e7a6ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "HTML(display_videos('fc_test9.mp4'))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hVRPgVCe4uC",
        "colab_type": "text"
      },
      "source": [
        "<font color='green'> **Comments:** </font>\n",
        "\n",
        "1) **The issues:** one main issue is that the agent does not explore the whole map, as it seems to oscillate between two positions whenever there is no positive rewards during his exploration.\n",
        "\n",
        "2) **Increasing temperature:** Increasing the temperture results in an increase in the number of positive rewards, therefore the agent will explore more areas because the positive rewards are nearby. As a sresult, the overall score will be higher."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3fpr1y8e4uD",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "<font color='blue'>__Question 10__</font> Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG3ZHBNWe4uE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,epsilon,decay=0.9,prefix=''):\n",
        "    score = 0\n",
        "    loss = 0\n",
        "    \n",
        "    for e in range(epoch):\n",
        "        # initialization\n",
        "        state = env.reset()\n",
        "\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        agent.set_epsilon(decay * agent.epsilon)\n",
        "\n",
        "        while not game_over:\n",
        "            #Agent takes an action\n",
        "            action=agent.act(state)\n",
        "            \n",
        "            #Update: next state, reward from the environment\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action,train=True)\n",
        " \n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win +=  reward\n",
        "            if reward < 0:\n",
        "                lose -= reward\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "        \n",
        "\n",
        "        # Save as a mp4\n",
        "        if (e) % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "        \n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {:.3f}/{:.3f} ({:.3f}), epsilon {:.3f}\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose, epsilon))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "                \n",
        "            \n",
        "\n",
        "\n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size,grid_size))\n",
        "        \n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "    \n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "    def act(self, action, train = False):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = 0\n",
        "        reward = self.board[self.x, self.y] - train * self.malus_position[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "        \n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        \n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "        \n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state\n",
        "        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E3qE3hwe4uG",
        "colab_type": "code",
        "outputId": "b32a6418-c78f-47f4-edbb-f1161374cddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training\n",
        "# NEw parameters \n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=0.1,epsilon = 0.9, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent, env, epochs_train, epsilon = 0.9,decay =0.8,prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/050 | Loss 0.0276 | Win/lose count 9.500/23.100 (-13.600), epsilon 0.900\n",
            "Epoch 001/050 | Loss 0.0146 | Win/lose count 11.500/22.200 (-10.700), epsilon 0.900\n",
            "Epoch 002/050 | Loss 0.0142 | Win/lose count 5.000/22.700 (-17.700), epsilon 0.900\n",
            "Epoch 003/050 | Loss 0.0154 | Win/lose count 9.500/21.300 (-11.800), epsilon 0.900\n",
            "Epoch 004/050 | Loss 0.0144 | Win/lose count 9.000/17.800 (-8.800), epsilon 0.900\n",
            "Epoch 005/050 | Loss 0.0146 | Win/lose count 16.000/17.700 (-1.700), epsilon 0.900\n",
            "Epoch 006/050 | Loss 0.0122 | Win/lose count 17.000/17.900 (-0.900), epsilon 0.900\n",
            "Epoch 007/050 | Loss 0.0157 | Win/lose count 18.500/16.000 (2.500), epsilon 0.900\n",
            "Epoch 008/050 | Loss 0.0161 | Win/lose count 21.000/12.600 (8.400), epsilon 0.900\n",
            "Epoch 009/050 | Loss 0.0153 | Win/lose count 5.000/17.200 (-12.200), epsilon 0.900\n",
            "Epoch 010/050 | Loss 0.0165 | Win/lose count 12.000/16.000 (-4.000), epsilon 0.900\n",
            "Epoch 011/050 | Loss 0.0155 | Win/lose count 19.500/13.400 (6.100), epsilon 0.900\n",
            "Epoch 012/050 | Loss 0.0165 | Win/lose count 19.500/13.200 (6.300), epsilon 0.900\n",
            "Epoch 013/050 | Loss 0.0148 | Win/lose count 11.000/17.400 (-6.400), epsilon 0.900\n",
            "Epoch 014/050 | Loss 0.0181 | Win/lose count 15.500/16.400 (-0.900), epsilon 0.900\n",
            "Epoch 015/050 | Loss 0.0173 | Win/lose count 17.500/13.900 (3.600), epsilon 0.900\n",
            "Epoch 016/050 | Loss 0.0175 | Win/lose count 14.000/15.000 (-1.000), epsilon 0.900\n",
            "Epoch 017/050 | Loss 0.1030 | Win/lose count 15.500/14.700 (0.800), epsilon 0.900\n",
            "Epoch 018/050 | Loss 0.0154 | Win/lose count 17.000/14.900 (2.100), epsilon 0.900\n",
            "Epoch 019/050 | Loss 0.0188 | Win/lose count 16.000/14.500 (1.500), epsilon 0.900\n",
            "Epoch 020/050 | Loss 0.0883 | Win/lose count 19.500/15.100 (4.400), epsilon 0.900\n",
            "Epoch 021/050 | Loss 0.1098 | Win/lose count 20.500/13.800 (6.700), epsilon 0.900\n",
            "Epoch 022/050 | Loss 0.0235 | Win/lose count 18.500/13.900 (4.600), epsilon 0.900\n",
            "Epoch 023/050 | Loss 0.1169 | Win/lose count 13.000/16.100 (-3.100), epsilon 0.900\n",
            "Epoch 024/050 | Loss 0.0131 | Win/lose count 18.500/14.100 (4.400), epsilon 0.900\n",
            "Epoch 025/050 | Loss 0.0189 | Win/lose count 6.500/17.500 (-11.000), epsilon 0.900\n",
            "Epoch 026/050 | Loss 0.0121 | Win/lose count 13.500/16.800 (-3.300), epsilon 0.900\n",
            "Epoch 027/050 | Loss 0.0178 | Win/lose count 10.000/17.300 (-7.300), epsilon 0.900\n",
            "Epoch 028/050 | Loss 0.0133 | Win/lose count 22.000/13.400 (8.600), epsilon 0.900\n",
            "Epoch 029/050 | Loss 0.0102 | Win/lose count 20.500/13.600 (6.900), epsilon 0.900\n",
            "Epoch 030/050 | Loss 0.0105 | Win/lose count 6.500/17.700 (-11.200), epsilon 0.900\n",
            "Epoch 031/050 | Loss 0.0148 | Win/lose count 22.500/13.400 (9.100), epsilon 0.900\n",
            "Epoch 032/050 | Loss 0.0142 | Win/lose count 11.000/16.600 (-5.600), epsilon 0.900\n",
            "Epoch 033/050 | Loss 0.0137 | Win/lose count 9.500/16.500 (-7.000), epsilon 0.900\n",
            "Epoch 034/050 | Loss 0.0105 | Win/lose count 16.000/14.100 (1.900), epsilon 0.900\n",
            "Epoch 035/050 | Loss 0.0107 | Win/lose count 20.000/13.500 (6.500), epsilon 0.900\n",
            "Epoch 036/050 | Loss 0.0151 | Win/lose count 7.500/18.400 (-10.900), epsilon 0.900\n",
            "Epoch 037/050 | Loss 0.0112 | Win/lose count 24.000/12.800 (11.200), epsilon 0.900\n",
            "Epoch 038/050 | Loss 0.0095 | Win/lose count 8.500/17.400 (-8.900), epsilon 0.900\n",
            "Epoch 039/050 | Loss 0.0146 | Win/lose count 1.000/19.800 (-18.800), epsilon 0.900\n",
            "Epoch 040/050 | Loss 0.0168 | Win/lose count 17.000/14.100 (2.900), epsilon 0.900\n",
            "Epoch 041/050 | Loss 0.0784 | Win/lose count 21.500/14.000 (7.500), epsilon 0.900\n",
            "Epoch 042/050 | Loss 0.0123 | Win/lose count 7.500/17.600 (-10.100), epsilon 0.900\n",
            "Epoch 043/050 | Loss 0.0107 | Win/lose count 13.500/15.500 (-2.000), epsilon 0.900\n",
            "Epoch 044/050 | Loss 0.0097 | Win/lose count 8.000/17.000 (-9.000), epsilon 0.900\n",
            "Epoch 045/050 | Loss 0.0130 | Win/lose count 8.000/16.900 (-8.900), epsilon 0.900\n",
            "Epoch 046/050 | Loss 0.0143 | Win/lose count 5.000/17.700 (-12.700), epsilon 0.900\n",
            "Epoch 047/050 | Loss 0.0119 | Win/lose count 13.500/17.100 (-3.600), epsilon 0.900\n",
            "Epoch 048/050 | Loss 0.0131 | Win/lose count 2.000/19.400 (-17.400), epsilon 0.900\n",
            "Epoch 049/050 | Loss 0.0133 | Win/lose count 9.500/16.800 (-7.300), epsilon 0.900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCfXcnMue4uK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "8c74b9ff-49d6-4b14-e2b6-ddc90a686cc4"
      },
      "source": [
        "# Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 10.5/0. Average score (10.5)\n",
            "Win/lose count 6.0/0. Average score (8.25)\n",
            "Win/lose count 4.0/0. Average score (6.833333333333333)\n",
            "Win/lose count 3.5/0. Average score (6.0)\n",
            "Win/lose count 9.0/1.0. Average score (6.4)\n",
            "Win/lose count 12.0/1.0. Average score (7.166666666666667)\n",
            "Win/lose count 2.0/0. Average score (6.428571428571429)\n",
            "Win/lose count 9.0/0. Average score (6.75)\n",
            "Win/lose count 4.5/0. Average score (6.5)\n",
            "Win/lose count 7.0/0. Average score (6.55)\n",
            "Final score: 6.55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naRC2wnBe4uO",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mda11Nvxe4uQ",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}